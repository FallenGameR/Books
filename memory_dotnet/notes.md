# Pro memory management in dot NET

Rule 2 - Random Access Should Be Avoided, Sequential Access Should be Encouraged
================================================================================

RAM память для процессора медленная. Поэтому ВСЕ взаимодействие идет через L123 кеши. При обращении к массивам кеши заполняются правильно, при работе с древовидными структурами, которые разбросаны по памяти кеши постоянно инвалидируются.

Кроме того современная RAM память так устроена, что перед обращением к ней её нужно прогреть. Проревается весь ряд. Если прогрели ряд и не использовали его весь и теперь греем другой ряд, то тратиться время на прогрев. Время прогрева можно посмотреть в таймингах памяти типа 11-11-11.

А еще чтобы GC проверил связность объектов ему нужно пройти по ссылкам. Если в памяти связный список на миллион элементов его пройти тупо дольше чем массив.

Плюс поскольку стек постоянно используется, то его всегда можно найти в кеше.



Rule 12 - Avoid Unnecessary Heap References
===========================================

Generational Garbage Collection чтобы ускорить прохождение списов объектов в разных поколениях создает навые roots, если объект более старого поколения (кеш) используется для хранения объектов более молодого поколения. Внутри GC есть куча кода, которые все это трекает через card tables и remembered set механизмы.

Связности объектов между поколениями можно избежать, если например древовидную структуру хранить в массиве, а ссылки на элементы держать как индексы.



Rule 14 - Avoid Heap Allocations in Performance Critical Code Paths
===================================================================

При аллоцировании памяти есть быстрый code path если память есть, объект маленький (идет в Small Object Heap) и у него нет finalizer. При этом выделение памяти это просто инкремент указателя. Вяделеная память уже обнулена и вся инициализация объекта состоит в записи указателя на MEthod Table по адресу объекта. Код выделения при этом прописывается JIT'ом как короткая асеблерная вставка. Скорость выделения и инициалищациии при этом буквально наносекунды.

Но если хотя бы одно условие не соблюдено, то более медленный code path используется. Он там использует state machine и может привести к нескольким сборам мусора. Это уже десятки миллисекунд.

Так что если нужно чтобы всегда было быстро, сначала выделяем память, а потом её используем.



Rule 15 - Avoid Excessive LOH Allocations
=========================================

Выделения памяти из LOH более сложные, поскольку большая часть времени тратиться на обнуление памяти. В алокаторе код заточен на предотвращение фрагментации и реализован как более сложная state machine.

Обнулить память под большой объект - это десятки миллисекунд или вообще секунды.

Так что использовать пул объектов.



Rule 16 - Use stack allocations on hot allocation path
======================================================

Structs
-------

Начиная с C#7 можно использовать такую конструкцию:
Span<DataStruct> a = stackalloc DataStruct[list.Count];

И использовать её вместо создания кучи временных объектов в куче:
IEnumerable<DataClass> b = list.Select(i => new DataClass{...});

Производительность в показанном тесте лучше в 4 раза из-за того, что стек всегда в кеше, а ещё прегревать каждый раз новую линию в памяти при random access не надо.

Но тут важно не вылезти за стек. Автор книги говорит ограничиться 1kb памяти, а это в структуре из двух int получатся 128 объектов. То есть какой-то очень специфичный случай. А если за стек вылезти, то приложение уже не восстановить.

Array Pool
----------

В .NET есть класс который контролирует пул массивов: ArrayPool<int>.Shared.Rent(minLength); Возвращать pool.Return(); Внутри поддерживаются корзины массивов у которых длина растет x2, а память выделяется из thread local storage.

По замерам производительности в книге на искуственном примере данный подход получается еще эффективнее чем через структуры, поскольку память для массивов уже выделена в пуле.

Newtonsoft JSON умеет с ArrayPool работать - нужно выставить JsonTextReader.ArrayPool (почему он по умолчанию этого не делает?).



Rule 18 - Avoid Mid-Life Crysis
===============================

Чтобы не было утечек памяти, связанных с фрагментацией gen-2 нужно чтобы соблюдалось предположение, на котором основан GC. Либо объект временный и живет мало, либо он постоянный и живет долго. Если у нас в приложении куча временных данных, которая долго хранится, а потом выкидывается, то они окажутся во втором поколении и после sweep будут в нем дырами. А второе поколение убирается редко и compact дорогой из-за того что нужно двигать много битиков по памяти.

Так что временные объекты должны быстро терять все указатели на них и умирать в 0 поколении.



Rule 19 - Avoid Explicit GC
===========================

GC подстраивается под использование памяти конкретной программы, если вызывать его вручную его внутренние статистики инвалидируются.



Rule 22 - Avoid Pinning
=======================

GC умеет с pinned объектами работать, но поскольку их трогать нельзя из-за них начинается фрагментация и несколько сбивается механизм старения объектов.

Так что либо такие pinned объекты должны жить мало (fixed keyword внутри метода, который быстро выходит), либо долгоживущий буфер без разрывов внутри.








Finalizers
==========

Можно из кода внутри finalizer использовать managed объекты, пока finalizer не отработал те объекты достижимы и еще есть в памяти. Но вот порядок отработки finalizers не определен. Объект с которым ты работаешь из finalizer уже мог сам быть finalized. Finаlizer будет вызываться из специального finalizer thread, и их может быть несколько.

В C# дочерние классы в конце своего finalizer вызывают finalizer базового класса. Даже если произошел exception.

Если finalizer определен, то память под объект выделятеся в х50 раз медленее - не будет простого инкремента указателя. Объект нужно записать в finalization queue, при этом сдвигается часть этой очереди (то что уже готово к финалазиции), операция добавления блокирующая и добавлние может вызвать динамический рост finalization array. А для освобождения памяти ему нужен будет еще один GC. Пока его finalizer не отработал (а он запускается после GC) он еще и попадает в старшее поколение.

Finilizer может не отработать до конца (exception, убивает процесс), не быть вызван вообще (thread abort) или вызван несколько раз (resurection). Причем из-за resurection он может быть вызван несколько из нескольких потоков для одного и того же объекта.

CriticalFinilizer (SafeHandle) же всегда в любой ситуации будет иметь шанс - он будет по крайней мере вызван. Код таких critical finalizers предварительно будет JITted. Critical finalizer вызываются после того как отработали все обычные. Это дает возможность flush buffered data.


SafeHandle
==========

В P/Invoke API использовать вместо IntRef. Они сохраняют this пока не отработал код с unmanaged ресурсом. Иначе из-за eager root collection finalizer может отработать и закрыть доступ к ресурсу пока метод класса с ним работает.


Rule 25 - Avoid Finalizers
==========================

Из-за finalizer overhead (дольше выделяется память, дольше уходят из памяти) и из-за сложностей с написанием безопасного финализатора (реентерабельный, выполняется из другого потока, неизвестно состояние других объектов, нет гарантии что поток не выйдет, нельзя кидать исколючений, нельзя выделять память, не надо вызывать виртаульные методы) лучше финализаторы не писать вообще.

Вместо этого - SafeHandle (обернуть unmanaged ресурсы, все популярные хендлы уже обернули), explicit cleanup (Disposable).


Rule 26 - Prefer Explicit Cleanup
=================================

Использовать статический анализ кода чтобы поймать все что забыли вызвать.


Thread Local Storage
====================

[ThreadStatic] прогсто его использование не делает доступ к данным быстрее - там внутри есть серия редиректов и в итоге он ссылается на общую память. Но для сценарий кеширования, трасировки и логирования TLS позволяет многим потокам не наступать на пятки друг другу. ArrayPool<T> внутри им и пользуется.

Для асинхронных plinq вызовов поскольку мы не знаем на каком потоке код будет вызват TLS ThreadLocal<T> использовать нельзя. Но специально для таких случаев есть AsyncLocal<T>, который привязан к ExecutionContext, но не дает преимуществ по памяти.


Struct
======

В C#7+ появилось несколько новых видов struct, которые позволяют писать приложения более требовательные по памяти:

- readonly struct - гарантия что поля не поменяются
- ref / in аргумент - гарантия что не будет копирования при передачи параметром
- ref struct - гарантия что не будет алокации в heap, только на стеке. А значит многопоточная синхронизация не нужна (стеком нельзя делится между потоками) и область жизни строго определена использованием.
- unsafe struct / fixed int Buffer[128] - буфер алоцируется как часть структуры (а потом стек кончается, ага). Можно использовать в массивах массивов, которые алоцируются на куче. Тогда структура данных получается более плотная - не хранятся длины массивов и не используются отдельные объекты для под-массивов. Так что будет лучше использоваться кеш процессора.
- stackalloc вместо new - можно комбинировать с fixed int XXX[LEN] поскольку внутренний массив не будет алоцирован в куче (смотри чтобы стек не кончился)


Memory<T>/Span<T>
=================

Позволяют писать код, который не делает новых аллокаций и возможно ещё и не двигает объекты по памяти. В себе они энкапсулируют array (возможно pinned), string, pointer. Позволяют делать slicing.

Span<T> может жить только на стеке, поэтому его время жизни строго детерминировано и он всегда ложится в кеш процессора.

Memory<T> может жить в heap и поэтому её можно использовать в closures. Мemory порождает Span как factory. IMemoryOwner это тот кто должен вызвать Dispose. ArrayPool можно использовать для первоначального эффективного аллоцирования Memory.


Data-Oriented Code
==================

Эфективно использует кеш CPU. Данные храняться не как поля объектов, разбросанных по всех куче, а как группа массивов (один на поле), которые совместно описывают группу объектов. Ссылки не храняться как ссылки, а они индексы в массивах или ключи в словарях.

Примеры - Entity Component System in Unity и Structure of Arrays.


NullReference
=============

Первая страница памяти в OS (от 0 до 64kb = 0x1_000) всегда пустая. Поэтому попытки доступа по этим адресам вызывает NullReferenceException. Если же попытаться получить доступ к памяти к которой у тебя доступа нет в более высоких адресах, то будет AccessViolationException.

В JIT встроена защита, когда в случае AccessViolationException который получается при доступе к дальнему полю null объекта (или массиву null объектов) будет все равно брошен NullReferenceException вместо AccessViolationException.


GC API
======

GC.GetAllocatedBytesForCurrentThread - использовать в тестах чтобы убедиться что тестируемый код не алоцирует память

GCSettings.IsServerGC - проверить в runtime какой GC используется. Альтернатива - читать ETW.


ETW
====

PerfView для сбора. Под капотом использует TraceEvent library, которую выложили на GitHub.

Прочитать какой GC используется можно в Microsoft-Windows-DotNETRuntimeRundown/Runtime/Start. Это событие пишется и при старте сбора ETW логов. StartupFlags содержит информацию об используемом GC.
